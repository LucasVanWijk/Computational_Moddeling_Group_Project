{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inleiding\n",
    "Als eers hebben wij het csv naar een exel bestand omgezet en de data bekeken. Wij ontdekten de volgende punten.\n",
    "\n",
    "Wij er achter gekomen dat het moeilijk is om een wijn te identificeren. Zo kan een wijn uit hetzelfde jaar met dezelfde naam gereviewed door dezelfde persoon uit de zelfde streek andere chemische eigenschappen hebben. Dit roept vragen op. Namelijk zijn de wijnen hetzelfde en zo ja. Klopt de meting van de chemische eigenschappen dan wel. Wij hebben besloten er van uit te gaan dat wij de chemische eigenschappen kunnen vertrouwen. Dit omdat wij anders dusdanig beperkt zijn dat wij geen interessante correlaties kunnen maken en de opdracht dus niet voldaan kan worden. Wij weten dus niet in hoeverre de namen correct zijn. Dit kan voor problemen zorgen bij ML. \n",
    "Jaartal is niet specifiek aangegeven maar kan wel zeer bruikbaar zijn. Naar verkenning zijn wij er achter gekomen dat een titel wel vaak een jaar aangeeft. Wij hebben toen code geschreven om te kijken welke titels geen jaar bevat dit bleken er 4 te zijn.\n",
    "Na verkenning zijn wij er achter gekomen dat provincies niet altijd bestaande provincies zijn maar dat er ook regioâ€™s en onbruikbare waardes tussen zitten. Dit zorgt er dus voor dat wij niet soepel weerdata voor die regio kunnen opvragen en maakt een correlatie zoeken tussen weer in een regio en de  qualiteit van de wijn erg moeilijk Daarom kiezen wij ervoor om data van de hoofdstad te gebruiken i.p.v. data van verschillende plaatsen. De data van de hoofdstad (Lissabon) hebben we gevonden op www7.ncdc.noaa.gov/ dit is National Climatic Data Center van de United states department of commerce. Hier hebben wij de data van Lissabon van 1990 tot 2018 kunnen vinden.\n",
    "\n",
    "## Onderzoek vragen\n",
    "\n",
    "1. In hoeverre is de score van een Portugese Red te voorspellen op basis van de chemische kenmerken?\n",
    "2. Welk effect heeft weer over de jaren heen effect op de wijn score die reviewers geven in punten?\n",
    "3. Kan je op basis van score en prijs welke regio de wijn zijn oorsprong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeer nodige libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools as itertools\n",
    "import itertools\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset rode wijnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kiezen ervoor om de colommen country, variety en id te verwijderen, omdat Country alleen de value Portugal heeft evenals variety alleen de value Portuguese Red heeft. ID halen we weg, omdat deze niet handig is voor ons. We hoeven geen exact kolom aan te spreken. Het kan namelijk zijn dat 1 wijn meerdere beoordeelaars heeft of een beoordeelaar meerdere wijnen. Kort gezegd aan ID hebben we niks voor onze onderzoeksvragen.\n",
    "\n",
    "Daarnaast verwijderen we alle kolommen met NAN waardes erin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.000000</td>\n",
       "      <td>2060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>88.860194</td>\n",
       "      <td>24.703398</td>\n",
       "      <td>8.349272</td>\n",
       "      <td>0.529723</td>\n",
       "      <td>2.574587</td>\n",
       "      <td>0.087831</td>\n",
       "      <td>16.008252</td>\n",
       "      <td>47.775243</td>\n",
       "      <td>3.310869</td>\n",
       "      <td>0.662427</td>\n",
       "      <td>2011.600485</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.947800</td>\n",
       "      <td>25.716501</td>\n",
       "      <td>1.742572</td>\n",
       "      <td>0.180143</td>\n",
       "      <td>1.419112</td>\n",
       "      <td>0.047329</td>\n",
       "      <td>10.423659</td>\n",
       "      <td>33.478012</td>\n",
       "      <td>0.155111</td>\n",
       "      <td>0.173984</td>\n",
       "      <td>2.812603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.305000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090250</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            points        price  fixed acidity  volatile acidity  \\\n",
       "count  2060.000000  2060.000000    2060.000000       2060.000000   \n",
       "mean     88.860194    24.703398       8.349272          0.529723   \n",
       "std       2.947800    25.716501       1.742572          0.180143   \n",
       "min      81.000000     5.000000       4.600000          0.120000   \n",
       "25%      87.000000    12.000000       7.100000          0.400000   \n",
       "50%      88.000000    17.000000       7.900000          0.520000   \n",
       "75%      91.000000    28.000000       9.300000          0.635000   \n",
       "max     100.000000   450.000000      15.900000          1.580000   \n",
       "\n",
       "       residual sugar    chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "count     2060.000000  2060.000000          2060.000000           2060.000000   \n",
       "mean         2.574587     0.087831            16.008252             47.775243   \n",
       "std          1.419112     0.047329            10.423659             33.478012   \n",
       "min          0.900000     0.012000             1.000000              6.000000   \n",
       "25%          1.900000     0.070000             8.000000             23.000000   \n",
       "50%          2.200000     0.079000            14.000000             38.000000   \n",
       "75%          2.600000     0.090250            21.000000             65.000000   \n",
       "max         15.500000     0.610000            72.000000            289.000000   \n",
       "\n",
       "                pH    sulphates         year   count  \n",
       "count  2060.000000  2060.000000  2060.000000  2060.0  \n",
       "mean      3.310869     0.662427  2011.600485     1.0  \n",
       "std       0.155111     0.173984     2.812603     0.0  \n",
       "min       2.740000     0.330000  1996.000000     1.0  \n",
       "25%       3.210000     0.550000  2010.000000     1.0  \n",
       "50%       3.305000     0.620000  2012.000000     1.0  \n",
       "75%       3.400000     0.730000  2014.000000     1.0  \n",
       "max       4.010000     2.000000  2016.000000     1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lees het bestand in\n",
    "redwines = pd.read_csv(\"redwine.csv\", delimiter=\";\", encoding='iso-8859-1')\n",
    "\n",
    "# Verwijder onnodige kolommen\n",
    "redwines.drop(['country','variety','id'],axis=1, inplace=True)\n",
    "redwines.dropna(inplace=True)\n",
    "\n",
    "# Voeg jaartal toe als aparte kolom, en verwijder nan rijen voor jaren (2465 naar 2461)\n",
    "redwines['year'] = redwines['title'].str.extract(r\"([1][9][9]\\d|[2][0][0,1,2]\\d)\")\n",
    "redwines = redwines[redwines['year'].notnull()]\n",
    "redwines['year'] = redwines['year'].astype(int)\n",
    "redwines['count'] = 1\n",
    "\n",
    "# lees tabel statistieken uit\n",
    "redwines.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualisatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Correlatie__\n",
    "\n",
    "Als eerst is correlatie tabel gemaakt om inzicht te krijken in hoe hoog de correlatie tussen verschillende waarden zit. Dit gaf een iets treurig inzicht. De correlatie waarden zijn erg laag en er lijkt op het eerste ogenblik geen correlatie te zitten tussen de meesten van deze waarden. Zeker de weerwaarden lijken zeer weinig effect te hebben op de rest. De weerwaarden onderling hebben op logische wijs wel een hoge correlatie waarden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlatie tabel voor dataset redwines\n",
    "plt.figure(figsize=(16,12))\n",
    "correlation_matrix = redwines.drop(['description','title','count'],axis=1).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Puntenverdeling__\n",
    "\n",
    "Het is belangrijk om inzicht te hebben in hoe de punten zijn verdeeld. Na een korte analyse kwamen we erachter dat alle punten zijn verdeeld tussen 80 en 100. Daarmee is een wijn van 80 punten opeens de slechtst beoordeelde wijn terwijl het lijkt alsof dit een redelijk hoge score is. In onderstaande bar plot is te zien hoe de punten zijn verdeeld. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punt verdeling\n",
    "points = redwines.groupby('points').sum()\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xticks(points.index)\n",
    "plt.bar(points.index, points['count'])\n",
    "plt.xlabel('Points')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Boxplots__\n",
    "\n",
    "Wij hebben ook besloten om een paar box plotten te maken van specifieke waarden om zo te zien hoe die zijn verdeeld.\n",
    "Hier uit is te op te merken dat de pH relatief dicht bij elkaar ligt en dat er niet veel waarden zijn die er veel afwijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = redwines.boxplot('pH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier uit is te zien dat het suiker gehalte veel waardes zijn die ver afwijken. Intresant genoeg zijn al deze waarden hoger dan de mediaan en zijn er weinig waarden lager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = redwines.boxplot('residual sugar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gemiddelde prijs per score__\n",
    "\n",
    "We vroegen ons als groepje ook af wat de correlatie is tussen wijn prijs en gegeven punten. Je zou zeggen dat de duurdere wijnen ook beter beoordeeld moeten zijn. Het aantal punten zou dus moeten oplopen naarmate de prijs hoger wordt. Dit bleek ook enigzins het geval zoals in de onderstaande scatter plot te zien is. Het is soms ook lastig te zeggen aangezien het onderlinge verschil tussen gegeven punten niet erg hoog is. Er is per puntenaantal een gemiddeld van de prijs genomen, en dit gemiddelde wordt getoond per puntenaantal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points in vergelijking met gemiddelde prijs \n",
    "avg = redwines.groupby('points').sum()\n",
    "avg['avg_price_per_point'] = avg['price'] / avg['count']\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.xticks(avg.index)\n",
    "plt.plot(avg.index, avg['avg_price_per_point'])\n",
    "plt.xlabel('Points')\n",
    "plt.ylabel('Average price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemiddelde score per wijnproever\n",
    "avg = redwines.groupby('taster_name').sum()\n",
    "avg['avg_taster_given_points'] = avg['points'] / avg['count']\n",
    "plt.figure(figsize=(16,5))\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([80,95])\n",
    "plt.bar(avg.index, avg['avg_taster_given_points'])\n",
    "plt.ylabel('Average points')\n",
    "plt.xlabel('Taster')\n",
    "plt.xticks(avg.index, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Suikergehalte over de jaren heen__\n",
    "\n",
    "Zoals in onderstaande grafiek te zien is, heeft de suikergehalte over de jaren toegenomen met af en toe een uitschieter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verhoging van suikergehalte over de jaren\n",
    "avg = redwines.groupby('year').sum()\n",
    "avg['avg_increase_substance'] = avg['residual sugar'] / avg['count']\n",
    "plt.figure(figsize=(16,5))\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([1.0,3.0])\n",
    "plt.bar(avg.index, avg['avg_increase_substance'])\n",
    "plt.xticks(avg.index, rotation='vertical')\n",
    "plt.ylabel('Substance')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoek vraag 1\n",
    "#### Correlatie tussen chemische eigenschappen en score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wij willen graag weten of de score van een Portugese red te vorspellen is gegeven de chemische eigenschappen. Mocht dit namelijk zo zijn dan kunnen wij misschien ook in een later stadium achterhalen welke chemische eigenschappen en in welke hoeveelheid zorgen voor een hogere score. Dit is zeer belangrijke informatie die alle wijnbrouwerijen graag willen hebben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allereest zullen wij kijken of de .corr functie die inzicht probeert te geven in de correlatie tussen eigenschappen.\n",
    "Een correlatie kan vinden tussen de score en een andere eigenschap van de wijn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwines.corr()['points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit geeft geen goed vooruitzicht. Volgens de functie schijn er zeer weinig correlatie te zijn tussen de chemische eigenschappen en de score. Een conclusie dat er geen correlatie is lijk tot dusver het meest logisch.\n",
    "\n",
    "Wij zullen dit veder uitzoeken met behulp van algoritme. \n",
    "\n",
    "Allereerst maken wij een baseline. Een baseline is de simpelste oplossing voor een probleem en kijken welk resultaat die oplevert. Dit is handig omdat je zo kan zien hoe goed je algoritme daadwerkelijk scoort. ZO kan je intuÃ¯tief denken dat 80% accuracy een goede score is maar kan je bijvoorbeeld met willekeurig een getal kiezen op een accuracy van 78% uitkomen. Dan heeft je algoritme dus niet veel toegevoegde waarden. \n",
    "\n",
    "Voor onze baseline is gekozen om een continue de scoren 88 te voorspellen. Dit is namelijk het meest voorkomende getal(de modus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modus_pred = pd.Series(88, index=[redwines.index])\n",
    "accuracy_score(redwines['points'], modus_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De baseline heeft een score van circa 14%. Nu zullen wij een lineaire regressie model proberen te bouwen.\n",
    "\n",
    "Allereerste moeten we zorgen dat lineaire regressie kan worden uitgevoerd op de data set. Hiervoor moeten we dus alle strings wegehalen) en vervangen door andere waarden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwines.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de bovenstaande tabel is te zien dat de kolom 'density', 'citric acid' en 'alcohol' niet de juiste datatypen hebben. We willen hier floats hebben terwijl ze nu aangegeven worden als Strings. Om dit op te lossen gaan we over de kolommen heen en zetten iedere String om tot een float. Wanneer dit niet kan omdat de waarde dit niet toelaat wordt er een NaN ingevuld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwines['citric acid'] = pd.to_numeric(redwines['citric acid'], errors='coerce')\n",
    "redwines['density'] = pd.to_numeric(redwines['density'], errors='coerce')\n",
    "redwines['alcohol'] = pd.to_numeric(redwines['alcohol'], errors='coerce')\n",
    "\n",
    "pd.isnull(redwines).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit blijk dat er circa 180 waarden zijn die niet naar een float kunnen worden omgezet. Wij hebben besloten om deze waarden uit onze data te halen. Ze kunnen ook geÃ¯nterpoleerd worden  maar aangezien wij de correlatie tussen deze waarden en de scoren willen vergelijken moet onze data wel exact zijn en wij kunnen niet garanderen dat als er een correlatie zit die ook mee wordt genomen in het interpoleren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwines_strings_dropped = redwines.copy()\n",
    "redwines_strings_dropped.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreeÃ«r het lineare regressie object vanuit de module sklearn\n",
    "red_wine_linreg_model = LinearRegression()\n",
    "\n",
    "# Selecteren van kenmerken en doel\n",
    "X = redwines_strings_dropped.loc[:,'fixed acidity':]\n",
    "y = redwines_strings_dropped['points']\n",
    "\n",
    "# Verdelen van data in train en testdata\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(\"Aantal waarden in de training set: {0}\".format(len(X_train)))\n",
    "print(\"Aantal waardes in de test set: {0}\".format(len(X_test)))\n",
    "\n",
    "# Start leerproces\n",
    "red_wine_linreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het maken van het model, willen we graag weten welke coÃ«fficiÃ«nt het model heeft gekregen. Hieruit is namelijk op te maken hoe hoog het model de correlatie tussen bepaalde waarden inschat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'features': X.columns, 'coefficients': red_wine_linreg_model.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien we dat chorides veel invloed heeft. Ook hebben volatile acicity, sulphates en alcohol invloed op de lijn.\n",
    "Om te bepalen hoe of de voorspellende waarde overeenkomen met de werkelekheid. Laen we het algoritme voorspellingen laten met behulp van de test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line_model(target,features_list):\n",
    "    linregr_model = LinearRegression()\n",
    "    X = redwines_strings_dropped[features_list]\n",
    "    y = redwines_strings_dropped[target]\n",
    "\n",
    "    # CreeÃ«ren van een train en test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Start leerproces\n",
    "    linregr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Maken van voorspellingen met de testset\n",
    "    wine_regr_test_orig = linregr_model.predict(X_test)\n",
    "    wine_regr_test_rounded = np.rint(np.floor(linregr_model.predict(X_test)))\n",
    "\n",
    "    # Uitrekenen van de gemiddelde afwijking en uitrekenen van de root mean squared error\n",
    "    avg_dev = abs(wine_regr_test_orig - y_test).sum() / len(y_test)\n",
    "    print(\"LinearRegression model with the features: {0}\".format(features_list) )\n",
    "    print(\"Algemene score (met afronding): {0}\".format(accuracy_score(wine_regr_test_rounded, y_test)))\n",
    "    print(\"\\nGemiddelde afwijking: {0}\".format(avg_dev))\n",
    "    print(\"\\n\")\n",
    "\n",
    "make_line_model('points',[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\n",
    "            \"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"pH\",\"sulphates\",\"alcohol\"])\n",
    "make_line_model('points',[\"chlorides\",\"pH\",\"sulphates\",\"alcohol\"])\n",
    "make_line_model('points',[\"chlorides\"])\n",
    "make_line_model('points',[\"pH\"])\n",
    "make_line_model('points',[\"sulphates\"])\n",
    "make_line_model('points',[\"alcohol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De resultaten zijn dusdanig laag dat er geen correlatie is te vinden tussen de eigenschappen en de score. Een verklaring hiervoor is dat er wel een correlatie is maar dat het algoritme moeite heeft een precieze score te berekenen. Zo kan bijvoorbeeld meer sulfide wel gelijk staan aan een hogere score maar voorspelt het algoritme 90 in plaats van 91 dus word het als fout gerekend. Een oplossing hiervoor is om de punten in groepen te verdelen wij hebben in eerste instantie gekozen om ze in groepen van 2 op te delen.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_prize_groups(group_size):\n",
    "    # Wanneer je de laagste waaarde van de huidige waarde haalt heb je het verschil. \n",
    "    # Daarbij zie je dat alle groepen consistent stijgen.\n",
    "    # Je kan het nummber verdelen door de toename om een groep te krijgen.\n",
    "    # Voeg 1 toe om de groep te laten starten bij 1 en niet 0\n",
    "    \n",
    "    redwines_strings_dropped[\"Points group\"] = round((redwines_strings_dropped[\"points\"] - 81) / group_size + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_prize_groups(2)\n",
    "redwines_strings_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_line_model('Points group',[\"sulphates\"])\n",
    "make_line_model('Points group',[\"alcohol\"])\n",
    "make_line_model('Points group',[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\n",
    "            \"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"pH\",\"sulphates\",\"alcohol\"])\n",
    "\n",
    "print(\"score voor baseline\")\n",
    "modus_pred = pd.Series(4, index=[redwines_strings_dropped.index])\n",
    "accuracy_score(redwines_strings_dropped['Points group'], modus_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit blijkt dus dat ook als je het in groepen verdeeld en het algoritme niet meer de exacte score hoeft te weten maar alleen ongeveer de score te kunnen bepalen. Dat het nog steeds geen correlatie vind tussen de chemische eigenschappen en de score. Wij kunnen dus concluderen dat er door middel van lineaire regressie geen score te vinden valt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst moet de groepen worden weg geghaald. Dit was ik vergeten en dan zie je dat zij de punten gaat voorspellen op basis van \"Points group\" dit willen we natuurlijk niet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwines_strings_dropped_no_group = redwines_strings_dropped.copy()\n",
    "redwines_strings_dropped_no_group.drop([\"year\",\"count\",\"Points group\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_decision_tree(depth):\n",
    "    # CreeÃ«r de decision tree object\n",
    "    dec_tree = DecisionTreeClassifier(max_depth=depth)\n",
    "\n",
    "    # Selecteer de kenmerken en het doel\n",
    "    # .loc[:,'fixed acidity':] neemt alle collomen na 'fixed acidity' mee\n",
    "    X = redwines_strings_dropped_no_group.loc[:,'fixed acidity':]\n",
    "    y = redwines_strings_dropped_no_group['points']\n",
    "\n",
    "    X_train, X_analysis, y_train, y_analysis = train_test_split(X, y, random_state=0)\n",
    "    X_validate, X_test, y_validate, y_test = train_test_split(X_analysis, y_analysis, random_state=0, test_size=0.5)\n",
    "\n",
    "    # Fit de data\n",
    "    dec_tree.fit(X_train, y_train)\n",
    "\n",
    "    val_accuracy = dec_tree.score(X_validate, y_validate)\n",
    "    test_accuracy = dec_tree.score(X_test, y_test)\n",
    "    \n",
    "    return (val_accuracy, test_accuracy)\n",
    "\n",
    "#Dit zorgt er voor dat hij niet overfit\n",
    "for x in range(1, 25):\n",
    "    tree_result = tune_decision_tree(x)\n",
    "    print(\"n: {0}; accuracy validation: {1}; accuracy test: {2}\".format(x, tree_result[0], tree_result[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit valt tezien dat de decision tree wel degelijk hoger scoort. Maar het kan nog een fluke zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = 0\n",
    "test_accuracy = 0\n",
    "for x in range(1,250):\n",
    "    wine_decision_tree = DecisionTreeClassifier(max_depth=9)\n",
    "\n",
    "    # Select the features and target\n",
    "    X = redwines_strings_dropped_no_group.loc[:,'fixed acidity':]\n",
    "    y = redwines_strings_dropped_no_group['points']\n",
    "\n",
    "    # Split the data into a train set and analysis set\n",
    "    X_train, X_analysis, y_train, y_analysis = train_test_split(X, y, random_state=x)\n",
    "\n",
    "    # Split the data in test and validation sets\n",
    "    X_validate, X_test, y_validate, y_test = train_test_split(X_analysis, y_analysis, random_state=x, test_size=0.5)\n",
    "\n",
    "    # This will train the model\n",
    "    wine_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    val_accuracy += wine_decision_tree.score(X_validate, y_validate)\n",
    "    test_accuracy += wine_decision_tree.score(X_test, y_test)\n",
    "\n",
    "print(\"Validation score average = {0} \\nTest score average = {1}\".format(val_accuracy/250,test_accuracy/250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zij scoort dus gemiddeld aanzienelijk hoger dan de baseline. Hieruit kunnen wij dus concluderen dat er een correlatie zit tussen de chemsiche eigenschappen en de. Een extra test met groepen is overbodig omdat wij hier al kunnen zien dat er een correlatie zit.\n",
    "\n",
    "Conclusie de exacte invloeden zijn moeilijk te voorspellen maar er is wel degelijk een correlatie tussen de chemische eigenschappen en de punten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onderzoeksvraag 2\n",
    "Welk effect heeft weer over de jaren heen effect op de wijn score die reviewers geven in punten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Externe dataset weer Lissabon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het weer kan invloed hebben op het uiteindelijke wijnproduct, daarom hebben we een externe dataset over het weer in Lissabon toegevoegd. Deze zullen we gebruiken later in onze onderzoeksvragen. We hebben de volgende tabellen verwijdert: STN--,Unnamed: 5, Unnamed: 7, GUST, PRCP, SNDP en VISIB, omdat we niet konden achterhalen waarover de data ging.\n",
    "\n",
    "Een enkele uitschieter is uit de database gehaald, omdat buiten de range de we daar hebben gegeven de waardes ongeloofwaardig werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lees de externe dataset in\n",
    "weather_conditions = pd.read_csv(\"weatherdata_lisbon.csv\", delimiter=\";\", encoding='iso-8859-1')\n",
    "\n",
    "# Drop onbruikbare rijen en hernoem kolommen\n",
    "weather_conditions.drop(['STN---','Unnamed: 5','Unnamed: 7','GUST','PRCP','SNDP','VISIB'], axis=1,inplace=True)\n",
    "weather_conditions.dropna(inplace=True)\n",
    "weather_conditions.rename(columns={'YEARMODA': 'Year','DEWP':'Dewpoint Temperature','TEMP': 'Temperature','MAX':'Max Temperature','MIN':'Min Temperature','WDSP':'Windspeed','MXSPD':'Max Windspeed'},inplace=True)\n",
    "\n",
    "# Schoonmaken en transvormeren van datatypen \n",
    "# Ook de data veranderen van fahrenheit naar celcius\n",
    "weather_conditions['Max Temperature'] = (weather_conditions['Max Temperature'].str.replace(',','.').str.rstrip(\"*\").astype(float) - 32) / 1.8\n",
    "weather_conditions['Min Temperature'] = (weather_conditions['Min Temperature'].str.replace(',','.').str.rstrip(\"*\").astype(float) - 32) / 1.8\n",
    "weather_conditions['Temperature'] = (weather_conditions['Temperature'].str.replace(',','.').astype(float) - 32) / 1.8\n",
    "weather_conditions['Dewpoint Temperature'] = (weather_conditions['Dewpoint Temperature'].str.replace(',','.').astype(float) - 32) / 1.8\n",
    "weather_conditions['Windspeed'] = weather_conditions['Windspeed'].str.replace(',','.').astype(float)\n",
    "weather_conditions['Max Windspeed'] = weather_conditions['Max Windspeed'].str.replace(',','.').astype(float)\n",
    "weather_conditions['Year']= pd.to_datetime(weather_conditions['Year'].astype(str), format='%Y-%m-%d')\n",
    "\n",
    "# FRSHTT = Frost, Rain, Snow, Hail, Thunder, Thornado\n",
    "weather_conditions['FRSHTT'] = weather_conditions['FRSHTT'].apply(lambda x: '{0:0>6}'.format(x))\n",
    "weather_conditions['Frost'] = weather_conditions['FRSHTT'].str[0].astype(float)\n",
    "weather_conditions['Rain'] = weather_conditions['FRSHTT'].str[1].astype(float)\n",
    "weather_conditions['Snow'] = weather_conditions['FRSHTT'].str[2].astype(float)\n",
    "weather_conditions['Hail'] = weather_conditions['FRSHTT'].str[3].astype(float)\n",
    "weather_conditions['Thunder'] = weather_conditions['FRSHTT'].str[4].astype(float)\n",
    "weather_conditions['Tornado'] = weather_conditions['FRSHTT'].str[5].astype(float)\n",
    "weather_conditions.drop('FRSHTT',axis=1,inplace=True)\n",
    "\n",
    "# Verwijder uitschieters\n",
    "weather_conditions = weather_conditions[weather_conditions['Min Temperature'] < 50]\n",
    "weather_conditions = weather_conditions[weather_conditions['Max Temperature'] < 50]\n",
    "weather_conditions = weather_conditions[weather_conditions['Temperature'] < 50]\n",
    "weather_conditions = weather_conditions[weather_conditions['Windspeed'] < 50]\n",
    "weather_conditions = weather_conditions[weather_conditions['Max Windspeed'] < 50]\n",
    "weather_conditions = weather_conditions[weather_conditions['Dewpoint Temperature'] < 100]\n",
    "\n",
    "# Bereken gemiddelde eigenschappen per jaar\n",
    "weather_conditions['Count'] = 1\n",
    "average_weather_conditions_peryear = weather_conditions.groupby(weather_conditions['Year'].map(lambda x: x.year)).sum()\n",
    "average_weather_conditions_peryear = average_weather_conditions_peryear[['Temperature','Dewpoint Temperature','Windspeed','Max Windspeed','Max Temperature','Min Temperature','Frost','Rain','Snow','Hail','Thunder','Tornado']].div(average_weather_conditions_peryear['Count'], axis=0)\n",
    "average_weather_conditions_peryear.drop(pd.Int64Index([2018]), inplace=True) # 2018 heeft maar 1 meting\n",
    "\n",
    "# Samenvoegen red wines en externe dataset\n",
    "redwines_with_yeartemperatures = redwines.merge(average_weather_conditions_peryear, left_on='year', right_on='Year')\n",
    "\n",
    "# Lees tabel statistieken uit\n",
    "average_weather_conditions_peryear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees tabel statistieken uit\n",
    "average_weather_conditions_peryear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwines_with_yeartemperatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([15.0,20.0])\n",
    "plt.bar(average_weather_conditions_peryear.index, average_weather_conditions_peryear['Temperature'])\n",
    "plt.ylabel('Temperature average')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.15,0.5])\n",
    "plt.bar(average_weather_conditions_peryear.index, average_weather_conditions_peryear['Rain'])\n",
    "plt.ylabel('Rain average')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Correlatie tabel:__\n",
    "\n",
    "In onderstaande correlatie tabel is te hoe hoe weinig correlatie er te vinden is tussen gemiddelde weer per jaar en wijneigenschappen. Bij weer onderling is wel veel correlatie te vinden zoals tussen max windspeed en windspeed, min temperature en temperature. Dit zijn intuitief gezien geen rare resultaten.\n",
    "\n",
    "Ook zien we wat interessantere inzichten zowel de correlatie van windspeed en temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlatie tabel voor dataset redwines\n",
    "plt.figure(figsize=(18,14))\n",
    "correlation_matrix = redwines_with_yeartemperatures.drop(['description','title','count'],axis=1).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent and independent columns\n",
    "dependent = redwines_with_yeartemperatures['points']\n",
    "independent = redwines_with_yeartemperatures[['Temperature','Rain','Max Temperature']]\n",
    "\n",
    "# Test en train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent, dependent, random_state=0, test_size=0.1)\n",
    "\n",
    "# Opzetten en trainen van model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Testen en uitrekenen nauwkeurigheid\n",
    "#print(model.predict(X_test))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_columns = ['Temperature','Max Temperature','Windspeed', 'Max Windspeed', \"Dewpoint Temperature\", \"Frost\", \"Rain\", \"Snow\", \"Thunder\",\"Tornado\",\"Hail\"]\n",
    "all_columns = ['Temperature','Max Temperature', \"Frost\", \"Rain\"]\n",
    "combs = []\n",
    "all_combs_and_score = {}\n",
    "\n",
    "for i in range(1, len(all_columns)+1):\n",
    "    els = [list(x) for x in itertools.combinations(all_columns, i)]\n",
    "    combs.extend(els)\n",
    "\n",
    "for i in combs:\n",
    "    \n",
    "    for h in [0.1,0.2,0.3]:\n",
    "\n",
    "        dependent = redwines_with_yeartemperatures['Max Windspeed']\n",
    "        independent = redwines_with_yeartemperatures[i]\n",
    "\n",
    "        # Test en train set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent, dependent, random_state=0, test_size=h)\n",
    "\n",
    "        # Opzetten en trainen van model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Testen en uitrekenen nauwkeurigheid\n",
    "        all_combs_and_score[model.score(X_test,y_test)] = str(i)+\" met test size: \" + str(h)\n",
    "\n",
    "print(round(max(all_combs_and_score) * 100, 2),all_combs_and_score[max(all_combs_and_score)])\n",
    "\n",
    "# LinearRegression\n",
    "# LogisticRegression\n",
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent and independent columns\n",
    "independent = redwines_with_yeartemperatures[['Temperature','Rain','Max Temperature','year']]\n",
    "\n",
    "# Test en train set\n",
    "X_train, X_test = train_test_split(independent, random_state=0, test_size=0.1)\n",
    "\n",
    "# Opzetten en trainen van model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Testen en uitrekenen nauwkeurigheid\n",
    "#print(model.predict(X_test))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is zeer weinig correlatie te vinden tussen de 2 datasets. Het was enigzins te verwachten, omdat we niet op het weer per regio ingespeeld hebben maar het gemiddelde weer van Lissabon hebben genomen. Elke regio of gebied heeft immers zijn eigen weer, plant en oogst seizoenen. Als er meer data beschikbaar was geweest, en de data foutloos en accuraat was geweest (kolom province bevat niet alleen provincies) waren er mogelijk betere inzichten uit gekomen. De enige grote correlaties die gevonden zijn, zijn correlaties tussen de twee datasets onderling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Onderzoeksvraag 3\n",
    "Kan je op basis van score en prijs achterhalen in welke regio de wijn zijn oorsprong heeft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor deze onderzoeksvraag is de data onderzocht per maand. Om deze vraag te beantwoorden, kijk ik eerst naar correlaties tussen de data van de maanden. Deze zijn gepresenteerd hieronder in een heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het omzetten van alle data gegroepeert op maand\n",
    "redwines['count'] = 1\n",
    "avg_per_province = redwines.groupby('province').sum() \n",
    "avg_per_province.loc[:, \"points\":\"sulphates\"] = avg_per_province.loc[:, \"points\":\"sulphates\"].div(avg_per_province['count'], axis=0)\n",
    "avg_per_province['province'] = avg_per_province.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlatieschema van alle gemiddeldes van alle maanden\n",
    "correlation = avg_per_province.corr()\n",
    "sns.heatmap(correlation, annot=True, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tussen price en points zit een aardige correlatie. Wat betekent dat per regio de verhouding van punten gegeven door wijnproevers en de prijs aardig hoog ligt. Ook is de total sulfur dioxide ten opzichte van de sulfur vrije dioxide een aardige correlatie te vinden.\n",
    "\n",
    "Ik wil nu verder met de correlatie tussen price en points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemiddelde punten per regio\n",
    "avg_points_sorted = avg_per_province.sort_values(by=['points'])\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xticks(np.arange(27),(avg_points_sorted.index), rotation='vertical')\n",
    "plt.ylim(80, 95)\n",
    "plt.bar(avg_points_sorted['province'], avg_points_sorted['points'])\n",
    "plt.xlabel('province')\n",
    "plt.ylabel('points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "het gemiddelde aantal punten per regio liggen niet ver van elkaar af. Op basis van alleen punten zullen we dus niet kunnen concluderen welke regio de wijn vandaan komt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemiddelde prijs per regio\n",
    "avg_points_sorted = avg_per_province.sort_values(by=['price'])\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xticks(np.arange(27),(avg_points_sorted.index), rotation='vertical')\n",
    "plt.ylim(0, 45)\n",
    "plt.bar(avg_points_sorted['province'], avg_points_sorted['price'])\n",
    "plt.xlabel('province')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit de grafiek blijkt dat er best veel verschil zit tussen de gemiddelde prijs per provincie. Op basis van deze informatie ik een model bouwen welke a.d.h.v. prijs en score welke probeert te achterhalen waar de wijn vandaan komt.\n",
    "\n",
    "Op het moment ben ik benieuwd of er een duidelijk verband is tussen de prijs en punten per maand. Hiervoor brengt ik de vorige twee grafieken in kaart in een grafiek gecategoriseerd op maand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namen geven aan een variabel\n",
    "avg_price = avg_per_province['price']\n",
    "avg_points = avg_per_province['points']\n",
    "index = avg_per_province.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafiek van gemiddelde prijs en punten per provincie\n",
    "df = pd.DataFrame({'Avg_price': avg_price,\n",
    "                   'Avg_Points': avg_points}, index = index)\n",
    "axes = df.plot.bar(rot=90, subplots=True)\n",
    "axes[0].legend(loc=3)\n",
    "axes[1].legend(loc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ondanks de hogere correlatie (0,78) bij de heatmap tussen score en prijs gecategoriseerd per maand, zie ik niet heel veel bijzonders aan de grafiek hierboven. Een ding wat je wel kan waarnemen dat enkele provincies met gemiddeld hogere wijnprijzen een iets hogere gemiddelde score heeft. Zo ook met gemiddelde lage wijnprijzen en scores. Echter blijft dat een kleine ontdekking.\n",
    "\n",
    "Toch wil ik een model in elkaar zetten wat een voorspelling doet op basis van de hoofdvraag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omzetten van maand in een integer\n",
    "month = {}\n",
    "counter = 1\n",
    "for item in avg_per_province.index:\n",
    "    month[str(item)] = counter\n",
    "    counter+=1\n",
    "redwines['province'] = [month[str(item)] for item in redwines['province']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables een naam geven\n",
    "dependent = redwines['province']\n",
    "independent = redwines[['points', 'price']]\n",
    "\n",
    "# Een gemiddelde percentage als uitkomst nemen uit een x aantal testen\n",
    "scores_in_percentage = []    \n",
    "random_seed = 0\n",
    "testen = 10\n",
    "for i in range(testen):\n",
    "    \n",
    "    # Test en train set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent, dependent, random_state=random_seed, test_size=0.2)\n",
    "    random_seed+=1\n",
    "    \n",
    "    # Training model\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Voeg de score toe aan lijst met gevonden scores\n",
    "    scores_in_percentage.append(model.score(X_test, y_test))\n",
    "\n",
    "# Rekent het gemiddelde uit van alle percentuele scores    \n",
    "print(abs(((sum(scores_in_percentage)) / (len(scores_in_percentage))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat op viel was dat er 3 modellen aardig goed presteerden. De DecisionTreeClassifier functie aan top met een nauwkeurigheid van 33,3%. De functie logisticRegression had een nauwkeurigheid van 32,0% en DecisionTreeRegressor kwam met 14,5% nauwkeurigheid. Alle test zijn gedaan op basis van 10 testen en daarvan het gemiddelde.\n",
    "\n",
    "Uit deze informatie blijkt dat er aan de hand van deze dataset geen goede voorspelling kan worden gedaan waar de wijn vandaan komt.\n",
    "\n",
    "Hierna keek ik of er op basis van andere elementen een goede voorspelling kan worden gedaan. Ik heb nog maals enkele test gedaan met meer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables een naam geven\n",
    "dependent = redwines['province']\n",
    "independent = redwines[['total sulfur dioxide', 'price', 'points']]\n",
    "\n",
    "# Een gemiddelde percentage als uitkomst nemen uit een x aantal testen\n",
    "scores_in_percentage = []    \n",
    "random_seed = 0\n",
    "testen = 100\n",
    "for i in range(testen):\n",
    "    \n",
    "    # Test en train set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent, dependent, random_state=random_seed, test_size=0.2)\n",
    "    random_seed+=1\n",
    "    \n",
    "    # Training model\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Voeg de score toe aan lijst met gevonden scores\n",
    "    scores_in_percentage.append(model.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "# Rekent het gemiddelde uit van alle percentuele scores    \n",
    "print(abs(((sum(scores_in_percentage)) / (len(scores_in_percentage))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de functie DecisionTreeRegressor kan er tot 82,9 % nauwkeurigheid worden voorspelt welke regio er bij de wijn hoort op basis van totaal zwaveldioxide, prijs en punten.\n",
    "\n",
    "Nu ben ik erg benieuwd of het model veel kan halen uit een stuk of 8 willekeurige colums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables een naam geven\n",
    "dependent = redwines['province']\n",
    "independent = redwines[['points', 'price', 'fixed acidity', 'volatile acidity','residual sugar', 'total sulfur dioxide', 'chlorides']]\n",
    "\n",
    "# Een gemiddelde percentage als uitkomst nemen uit een x aantal testen\n",
    "scores_in_percentage = []    \n",
    "random_seed = 0\n",
    "testen = 10\n",
    "for i in range(testen):\n",
    "    \n",
    "    # Test en train set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent, dependent, random_state=random_seed, test_size=0.2)\n",
    "    random_seed+=1\n",
    "    \n",
    "    # Training model\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Voeg de score toe aan lijst met gevonden scores\n",
    "    scores_in_percentage.append(model.score(X_test, y_test))\n",
    "\n",
    "# Rekent het gemiddelde uit van alle percentuele scores    \n",
    "print(abs(((sum(scores_in_percentage)) / (len(scores_in_percentage))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Door vorige trainingssessies van modellen is er te zien dat de functie DecisionTreeRegressor vaak het beste uit de test komt. Door het combineren van de punten points, price, fixed acidity, volatile acidity, residual sugar, total sulfur dioxide, chlorides, kan er met 92,4% nauwkeurigheid gegokt worden waar de wijn vandaan komt.\n",
    "\n",
    "Mijn conclusie is dat er op basis van punten en scores geen voorspelling kan worden gemaakt waar de wijn vandaan komt, dat komt voornamelijk doordat points voor de wijn te dicht op elkaar ligt. Echter wanneer er meer parameters worden meegenomen, is er met 92,4% zekerheid te zeggen waar de wijn vandaan komt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothese toets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_sample = np.array([3.41, 3.51, 3.39, 3.11, 3.21, 3.50, 3.46, 3.37, 3.71]) # steekproef data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nul Hypothese (H0):__\n",
    "\n",
    "_Er is geen significant verschil te vinden tussen de gemiddelde PH waardes van de steekproef en de populatie. Dat wil zeggen, als de z score aan de boven en onderkant binnen -1.960 en 1.960 (2,5% links en rechts, 95% in het midden) valt, is er geen significant verschil te vinden_\n",
    "\n",
    "_Als de P waarde hoger is dan de alpha waarde, is er ook geen significant verschil._\n",
    "\n",
    "__Alternatieve Hypothese (HA):__\n",
    "\n",
    "_Er is wel een significant verschil tussen gemiddelde PH waardes van de steekproef en de populatie. Dat wil zeggen, als de z score aan de boven of onderkant buiten -1.960 en 1.960 (2,5% links en rechts, 95% in het midden) valt, is er wel een significant verschil te vinden_\n",
    "\n",
    "_Als de P waarde lager is dan de alpha waarde, is er ook een significant verschil._\n",
    "\n",
    "__Toetszijde(s):__\n",
    "\n",
    "_Het gaat om tweezijdig (beide zijdes) toetsen, aangezien we een significant verschil zoeken, een verschil kan zowel aan de lage kant als aan de hoge kant zitten._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eerst de steekproef- en populatiestatistieken berekenen\n",
    "\n",
    "# steekproefstatistieken\n",
    "x_ = ph_sample.mean() # Gemiddelde van de steekproef\n",
    "n = len(ph_sample) # Grootte steekproef\n",
    "s = ph_sample.std()\n",
    "\n",
    "# populatiestatistieken\n",
    "population = len(redwines_with_yeartemperatures['pH'])\n",
    "sigma = redwines_with_yeartemperatures['pH'].std() # Standaard deviatie van de populatie\n",
    "mu = redwines_with_yeartemperatures['pH'].mean() # Gemiddlede van de populatie\n",
    "\n",
    "# margin of error en standard error\n",
    "alpha = 0.05 # 95% betrouwbaarheid\n",
    "se = sigma / np.sqrt(n) # standard error using sigma of population, since its available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot de normaalverdeling met gemiddelde van populatie en gemiddelde van steekproef\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "plt.figure(figsize=(15,8), dpi=75)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma), color='green')\n",
    "plt.plot([mu,mu],[0,2],color='red', label='Population average') # gemiddelde populatie\n",
    "plt.plot([x_,x_],[0,2],color='blue', label='Sample average') # gemiddelde steekproef\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Methode 1:\\n\")\n",
    "\n",
    "sample_z_score = (x_ - mu) / se\n",
    "sample_alpha = stats.norm.pdf(sample_z_score)\n",
    "\n",
    "print(\"Steekproef:\")\n",
    "print(\"Z Score Steekproef:\\n\", sample_z_score)\n",
    "print(\"P waarde steekproef:\\n\", sample_alpha)\n",
    "\n",
    "population_z_score = stats.norm.ppf((1 - alpha / 2)) # 2 zijdig 0.975\n",
    "\n",
    "print(\"\\nPopulatie:\")\n",
    "print(\"Z Score middelste 95% populatie (2,5 links en rechts):\\n\", population_z_score)\n",
    "print(\"Margin of error populatie:\\n\", alpha)\n",
    "\n",
    "print(\"\\nSteekproef kans is hoger dan alpha populatie, dus verwerp HA : ~0.06 > 0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Methode 2:\\n\")\n",
    "\n",
    "z_score_left = ((x_ - mu) / se) * -1\n",
    "z_score_right = (x_ - mu) / se\n",
    "grens_ph_sample_left = z_score_left * se + x_\n",
    "grens_ph_sample_right = z_score_right * se + x_\n",
    "\n",
    "print(\"Steekproef:\")\n",
    "print(\"Z Score Steekproef links en rechts met SE \"+str(se)+\":\\n\", z_score_left, z_score_right)\n",
    "print(\"Grens PH waarde links en rechts:\\n\", grens_ph_sample_left, grens_ph_sample_right)\n",
    "\n",
    "z_score_left = stats.norm.ppf((alpha / 2)) # 2 zijdig 0.025\n",
    "z_score_right = stats.norm.ppf((1 - alpha / 2)) # 2 zijdig 0.975\n",
    "grens_ph_population_left = z_score_left * sigma + mu\n",
    "grens_ph_population_right = z_score_right * sigma + mu\n",
    "\n",
    "print(\"\\nPopulatie:\")\n",
    "print(\"Z Score 2,5% links en 97,5% rechts met SD \"+str(sigma)+\":\\n\", z_score_left, z_score_right)\n",
    "print(\"Grens PH waarde links en rechts:\\n\", grens_ph_population_left, grens_ph_population_right)\n",
    "\n",
    "print(\"\\n\\nDe alternatieve hypothese (HA) vervalt omdat er is geen significant verschil tussen de gemiddelde PH waarde \"\n",
    "      \"van de steekproef en de populatie is. Zowel de Z scores als de bijbehorende PH waardes vallen binnen de 95%\"\n",
    "      \" van de populatie. Dat de steekproef data (sample) binnen de 95% van de gehele populatie valt is uitgebeeld in\"\n",
    "      \" onderstaande grafiek. Alternatieve Hypothese (HA) vervalt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "plt.figure(figsize=(15,8), dpi=75)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma),color='green')\n",
    "plt.plot([grens_ph_sample_left,grens_ph_sample_left],[0,2],color='blue', label='Sample')\n",
    "plt.plot([grens_ph_sample_right,grens_ph_sample_right],[0,2],color='blue')\n",
    "plt.plot([grens_ph_population_left,grens_ph_population_left],[0,2],color='red', label='95% of Population')\n",
    "plt.plot([grens_ph_population_right,grens_ph_population_right],[0,2],color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Een interactieve visualisatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
